{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import tweepy\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input your Twitter developer account\n",
    "\n",
    "consumer_key = \"\"   \n",
    "consumer_secret = \"\"   \n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweepy settings\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)   \n",
    "auth.set_access_token(access_token, access_token_secret)   \n",
    "api = tweepy.API(auth)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to collect Tweet and transform the result into a data frame\n",
    "# e.g. envronment name='Development', query='vegan', fromDate='201101012315', toDate='201102012315', searchsize =100\n",
    "# search size should be at least 100, and be n*100, like 100, 200, 300 etc.\n",
    "\n",
    "def search_tweet(environmentname, fromdate, todate, keywords, searchsize, savedfilename): \n",
    " \n",
    "\n",
    "    idlist=[]\n",
    "    tweets=tweepy.Cursor(api.search_full_archive,\n",
    "                     environment_name=environmentname, query=keywords, fromDate=fromdate, toDate=todate,).items(searchsize)\n",
    "    for tweet in tweets: \n",
    "        idlist.append(tweet.id)\n",
    "    \n",
    "    \n",
    "    columns = set()\n",
    "    tweets_data = []\n",
    "    \n",
    "\n",
    "    while len(idlist)>=100:\n",
    "        idlistcurr=idlist[:100]\n",
    "        status2=api.statuses_lookup(idlistcurr,tweet_mode=\"extended\")\n",
    "\n",
    "\n",
    "        for status in status2:\n",
    "            status_dict = dict(vars(status))\n",
    "            keys = status_dict.keys()\n",
    "            single_tweet_data = {\"user\": status.user.screen_name}\n",
    "            for k in keys:\n",
    "                try:\n",
    "                    v_type = type(status_dict[k])\n",
    "                except: # make sure no none error\n",
    "                    v_type = None\n",
    "                if v_type != None: # make sure no none error\n",
    "                    single_tweet_data[k] = status_dict[k]\n",
    "                    columns.add(k)\n",
    "            tweets_data.append(single_tweet_data)\n",
    "        idlist=idlist[100:]\n",
    "\n",
    "\n",
    "    header_cols = list(columns)\n",
    "    header_cols.append(\"user\")\n",
    "\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    df.to_csv(savedfilename)\n",
    "    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to collect tweets of each period. Here I used two environment, 'research' and 'Development'. \n",
    "\n",
    "If running the following code, please set Twitter access keys above and replace the environment name below.  \n",
    "\n",
    "The nine files are available in the GitHub. However, since GitHub only allows files smaller than 25MB, the files on GitHub only contains tweet text and created time.If you want to collect tweets yourself and have the full result, run the code below. Otherwise you can jump to the next section (pre-processing) with the nine files in GitHub.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res1=search_tweet('research', '202104012315', '202104202315', 'vaccine uk', 1200, '2021Apr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res2=search_tweet('research', '202010012315', '202010202315', 'vaccine uk', 1200, '2020Oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res3=search_tweet('research', '202004012315', '202004202315', 'vaccine uk', 1200, '2020Apr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res4=search_tweet('research', '201910012315', '201910202315', 'vaccine uk', 1200, '2019Oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res5=search_tweet('research', '201904012315', '201904202315', 'vaccine uk', 1200, '2019Apr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res6=search_tweet('Development', '201810012315', '201810202315', 'vaccine uk', 1200, '2018Oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res7=search_tweet('Development', '201804012315', '201804202315', 'vaccine uk', 1200, '2018Apr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res8=search_tweet('Development', '201710012315', '201710202315', 'vaccine uk', 1200, '2017Oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res9=search_tweet('research', '201704012315', '201704202315', 'vaccine uk', 1200, '2017Apr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
